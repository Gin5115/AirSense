{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e94cfc1-f628-4f0d-b229-86e46e3c7c76",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">CS3006 Machine Learning Algorithms     : CIA 2</h1>\n",
    "<h1 style=\"text-align: center;\">CS3802 Machine Learning Algorithms Lab : Ex 9</h1>\n",
    "<h2 style=\"text-align: center;\">21011102079</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3174d4-e4fc-41dc-9782-3ba86b306e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Mean Squared Error = 188.63024391607598\n",
      "Iteration 10: Mean Squared Error = 24.946640659054214\n",
      "Iteration 20: Mean Squared Error = 16.89406625914018\n",
      "Iteration 30: Mean Squared Error = 14.636243420114193\n",
      "Iteration 40: Mean Squared Error = 13.1983513176674\n",
      "Iteration 50: Mean Squared Error = 12.255462774759991\n",
      "Iteration 60: Mean Squared Error = 11.568643686999469\n",
      "Iteration 70: Mean Squared Error = 11.034854579866995\n",
      "Iteration 80: Mean Squared Error = 10.570555461211624\n",
      "Iteration 90: Mean Squared Error = 10.135417635178506\n",
      "Iteration 100: Mean Squared Error = 9.687461380329964\n",
      "Iteration 110: Mean Squared Error = 9.306931530827645\n",
      "Iteration 120: Mean Squared Error = 8.9638925975718\n",
      "Iteration 130: Mean Squared Error = 8.647371433023658\n",
      "Iteration 140: Mean Squared Error = 14.205623372813191\n",
      "Iteration 150: Mean Squared Error = 9.578657633493348\n",
      "Iteration 160: Mean Squared Error = 9.729591972736522\n",
      "Iteration 170: Mean Squared Error = 9.041424497967405\n",
      "Iteration 180: Mean Squared Error = 8.707685796044311\n",
      "Iteration 190: Mean Squared Error = 8.358812568988382\n",
      "Test Mean Squared Error: 17.819319925435504\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "\n",
    "np.random.seed(42)\n",
    "weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
    "weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_iterations = 200\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    hidden_output = sigmoid(np.dot(X_train, weights_input_hidden))\n",
    "    predicted_output = np.dot(hidden_output, weights_hidden_output)\n",
    "\n",
    "    output_error = y_train.reshape(-1, 1) - predicted_output\n",
    "    output_delta = output_error\n",
    "    hidden_error = output_delta.dot(weights_hidden_output.T)\n",
    "    hidden_delta = hidden_error * sigmoid_derivative(hidden_output)\n",
    "\n",
    "    weights_hidden_output += hidden_output.T.dot(output_delta) * learning_rate\n",
    "    weights_input_hidden += X_train.T.dot(hidden_delta) * learning_rate\n",
    "\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        mse = mean_squared_error(y_train, predicted_output)\n",
    "        print(f\"Iteration {i}: Mean Squared Error = {mse}\")\n",
    "\n",
    "\n",
    "hidden_output = sigmoid(np.dot(X_test, weights_input_hidden))\n",
    "predicted_output = np.dot(hidden_output, weights_hidden_output)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, predicted_output)\n",
    "print(f\"Test Mean Squared Error: {test_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a45ee7e-c3d9-478d-88cd-8bf706909fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsath\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Test Mean Squared Error (Keras): 16.77030595860888\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Fetch the dataset\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "# Split data into features and target\n",
    "X = data[:, :-1]\n",
    "y = target\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define neural network architecture using Keras\n",
    "model = Sequential([\n",
    "    Dense(32, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "test_mse_keras = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test Mean Squared Error (Keras): {test_mse_keras}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6bbd2-9bb8-48d0-b76b-92793a90193e",
   "metadata": {},
   "source": [
    "Custom Neural Network vs. Keras Model:\r\n",
    "\r\n",
    "Both the custom neural network implementation and the Keras model achieved similar results in terms of test mean squared error.\r\n",
    "This indicates that both approaches are effective for solving the regression problem on the Boston housing datase\n",
    "t.\r\n",
    "Ease of Use:\r\n",
    "\r\n",
    "Keras provides a high-level API that abstracts away many details of building and training neural networks, making it easier to implement and experiment with different architectures and hyperparameters.\r\n",
    "The custom implementation requires more manual coding and understanding of neural network fundamentals but offers more flexibility and control over the\n",
    " model.\r\n",
    "Performance:\r\n",
    "\r\n",
    "Both implementations achieved relatively good performance on the regression task, as evidenced by the low test mean squared error.\r\n",
    "The performance could potentially be improved further by tuning hyperparameters such as learning rate, number of hidden units, and number\n",
    " of epochs.\r\n",
    "Scalability:\r\n",
    "\r\n",
    "For larger and more complex neural network architectures, Keras may be preferable due to its ease of use and scalability.\r\n",
    "Custom implementations may become cumbersome to manage as the complexity of the m\n",
    "odel increases.\r\n",
    "Resource Requirements:\r\n",
    "\r\n",
    "Keras relies on TensorFlow, Theano, or CNTK as backend engines, which may require additional resources for installation and execution.\r\n",
    "Custom implementations may have lower resource requirements since they don't rely on external libraries beyond NumPy and pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
