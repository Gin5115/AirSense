{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae916b5-2c37-4248-84b2-96be8e5c649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data  = pd.read_csv(r\"D:/snu/academic/sem6/ML_Lab/Lab4/classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ea7588-8eeb-438b-aef7-f74d4fd537b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d941e3-2eff-448d-b6f3-8b13fd2bd61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa3cca42-1df8-4373-aeeb-02d8e6706fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='gini',max_depth= 5)\n",
    "tree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c50aa3be-be31-471a-bac1-05c87abbe2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb9934ad-3ef2-4e30-ad66-049f0bce9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7cfa85e-972a-42f6-a626-c0f449d39a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  2],\n",
       "       [ 3, 29]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8db01c88-0edf-4ecc-b302-1fc709cbedd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a1ee03-2428-47f5-bd18-764faa50c7b3",
   "metadata": {},
   "source": [
    "# 1. Use the classification.csv file and compute the gini index for age and salary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a65a756-32d3-4597-93eb-c545b6f39022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv(r\"D:/snu/academic/sem6/ML_Lab/Lab4/classification.csv\")\n",
    "zc = df['Purchased'].value_counts().get(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abea6d1f-cab7-4948-99ff-fcb8728abf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of zero: 257\n"
     ]
    }
   ],
   "source": [
    "print(\"No of zero:\", zc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad0fc2a6-5c27-4ce0-9168-696c66b63e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini_index(dataframe, target_column):\n",
    "    total_samples = len(dataframe)\n",
    "    \n",
    "    class_proportions = dataframe[target_column].value_counts() / total_samples\n",
    "    \n",
    "    squared_proportions = class_proportions ** 2\n",
    "    \n",
    "    gini_index = 1 - squared_proportions.sum()\n",
    "    \n",
    "    return gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c68121ef-e57a-4885-af48-5014abbb6710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Index: 0.45938750000000006\n"
     ]
    }
   ],
   "source": [
    "gini_index = calculate_gini_index(df, 'Purchased')\n",
    "\n",
    "print(\"Gini Index:\", gini_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "790d9b13-a182-4547-9d5a-7a003be44ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini_index_by_category(dataframe, feature1, feature2, target_column):\n",
    "    total_samples = len(dataframe)\n",
    "    gini_index_total = 0.0\n",
    "    \n",
    "    for value1 in dataframe[feature1].unique():\n",
    "        subset_feature1 = dataframe[dataframe[feature1] == value1]\n",
    "        \n",
    "        for value2 in subset_feature1[feature2].unique():\n",
    "            subset_feature2 = subset_feature1[subset_feature1[feature2] == value2]\n",
    "            \n",
    "            gini_index_subset = calculate_gini_index(subset_feature2, target_column)\n",
    "            \n",
    "            weight = len(subset_feature2) / total_samples\n",
    "            gini_index_total += weight * gini_index_subset\n",
    "    \n",
    "    return gini_index_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6af8e1d4-9fac-4082-9258-4153d45debdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini_index(dataframe, target_column):\n",
    "    total_samples = len(dataframe)\n",
    "    \n",
    "    class_proportions = dataframe[target_column].value_counts() / total_samples\n",
    "    squared_proportions = class_proportions ** 2\n",
    "    gini_index = 1 - squared_proportions.sum()\n",
    "    \n",
    "    return gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ac26a19-5540-4047-ab7c-4c09d04df64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Index for Age and EstimatedSalary categories: 0.005\n"
     ]
    }
   ],
   "source": [
    "gini_index = calculate_gini_index_by_category(df, 'Age', 'EstimatedSalary', 'Purchased')\n",
    "\n",
    "print(\"Gini Index for Age and EstimatedSalary categories:\", gini_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafa320-9d85-4e69-9ae1-a34d82528b7b",
   "metadata": {},
   "source": [
    "# 2. Create decision tree algorithm from scratch without using sklearn library. you may assume that all the columns in the data will be categorical in nature. Give a new data for prediction and print the predicted output along with the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5910fd3-feae-4ee3-be8c-12313b6e808c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: [0]\n",
      "Predicted Probabilities: [{0: 1.0}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "\n",
    "    def calculate_gini(self, labels):\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        probabilities = counts / len(labels)\n",
    "        gini = 1 - np.sum(probabilities**2)\n",
    "        return gini\n",
    "\n",
    "    def calculate_information_gain(self, data, feature, target):\n",
    "        gini_parent = self.calculate_gini(data[target])\n",
    "\n",
    "        unique_values = data[feature].unique()\n",
    "        weighted_gini_child = 0\n",
    "\n",
    "        for value in unique_values:\n",
    "            subset = data[data[feature] == value]\n",
    "            weight = len(subset) / len(data)\n",
    "            gini_child = self.calculate_gini(subset[target])\n",
    "            weighted_gini_child += weight * gini_child\n",
    "\n",
    "        information_gain = gini_parent - weighted_gini_child\n",
    "        return information_gain\n",
    "\n",
    "    def find_best_split(self, data, target):\n",
    "        features = data.columns[:-1]  \n",
    "        best_feature = None\n",
    "        best_information_gain = -1\n",
    "\n",
    "        for feature in features:\n",
    "            information_gain = self.calculate_information_gain(data, feature, target)\n",
    "\n",
    "            if information_gain > best_information_gain:\n",
    "                best_feature = feature\n",
    "                best_information_gain = information_gain\n",
    "\n",
    "        return best_feature\n",
    "\n",
    "    def build_tree(self, data, target):\n",
    "        unique_labels = data[target].unique()\n",
    "\n",
    "        if len(unique_labels) == 1:\n",
    "            return {'label': unique_labels[0]}\n",
    "\n",
    "        if len(data.columns) == 1:\n",
    "            majority_label = data[target].mode().iloc[0]\n",
    "            return {'label': majority_label}\n",
    "\n",
    "        best_feature = self.find_best_split(data, target)\n",
    "\n",
    "        unique_values = data[best_feature].unique()\n",
    "        sub_trees = {}\n",
    "        for value in unique_values:\n",
    "            subset = data[data[best_feature] == value]\n",
    "            sub_trees[value] = self.build_tree(subset.drop(columns=[best_feature]), target)\n",
    "\n",
    "        return {'feature': best_feature, 'sub_trees': sub_trees}\n",
    "\n",
    "    def fit(self, data, target):\n",
    "        self.tree = self.build_tree(data, target)\n",
    "\n",
    "    def predict_instance(self, instance, tree):\n",
    "        if 'label' in tree:\n",
    "            return tree['label']\n",
    "        else:\n",
    "            feature_value = instance[tree['feature']]\n",
    "            if feature_value in tree['sub_trees']:\n",
    "                return self.predict_instance(instance, tree['sub_trees'][feature_value])\n",
    "            else:\n",
    "                return list(tree['sub_trees'].values())[0]['label']\n",
    "\n",
    "    def predict_proba_instance(self, instance, tree):\n",
    "        if 'label' in tree:\n",
    "            return {tree['label']: 1.0}\n",
    "        else:\n",
    "            feature_value = instance[tree['feature']]\n",
    "            if feature_value in tree['sub_trees']:\n",
    "                return self.predict_proba_instance(instance, tree['sub_trees'][feature_value])\n",
    "            else:\n",
    "                return self.predict_proba_instance(instance, list(tree['sub_trees'].values())[0])\n",
    "\n",
    "    def predict(self, data):\n",
    "        predictions = []\n",
    "        for _, instance in data.iterrows():\n",
    "            predictions.append(self.predict_instance(instance, self.tree))\n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        probabilities = []\n",
    "        for _, instance in data.iterrows():\n",
    "            probabilities.append(self.predict_proba_instance(instance, self.tree))\n",
    "        return probabilities\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Age': ['Young', 'Young', 'Young', 'Middle-aged', 'Middle-aged', 'Middle-aged', 'Senior', 'Senior', 'Senior'],\n",
    "    'Salary': ['Low', 'Low', 'High', 'Low', 'Low', 'High', 'Low', 'Low', 'High'],\n",
    "    'Purchased': [0, 0, 1, 0, 1, 1, 1, 0, 1]\n",
    "})\n",
    "\n",
    "tree_model = DecisionTree()\n",
    "\n",
    "tree_model.fit(data, target='Purchased')\n",
    "\n",
    "new_data_instance = pd.DataFrame({'Age': ['Young'], 'Salary': ['Low']})\n",
    "\n",
    "prediction = tree_model.predict(new_data_instance)\n",
    "probabilities = tree_model.predict_proba(new_data_instance)\n",
    "\n",
    "print(\"Predicted Output:\", prediction)\n",
    "print(\"Predicted Probabilities:\", probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
